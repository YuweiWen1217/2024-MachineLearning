# 2024-MachineLearning
This is a repository of code related to Machine Learning course.

## 实验一：基于kNN 的手写数字识别
实验条件：给定semeion手写数字数据集，给定kNN分类算法
实验要求：
1. 初级要求：编程实现kNN算法；给出在不同k值（5，9，13）情况下，kNN算法对手写数字的识别精度（要求采用留一法）
2. 中级要求：与机器学习包或平台(如weka)中的kNN分类器结果进行对比，性能指标为精度ACC，其他指标如归一化互信息NMI、混淆熵CEN任选其一（或两者）
3. 高级要求：采用旋转等手段对原始数据进行处理，进行至少两个方向（左上，左下）旋转，采用CNN或其他深度学习方法实现手写体识别

## 实验二：回归模型
### 初级要求
将数据集winequality-white.csv按照4:1划分为训练集和测试集。
1. 构造线性回归模型，并采用批量梯度下降**和**随机梯度下降进行优化；输出训练集和测试集的均方误差（MSE），画出MSE收敛曲线。
2. 对于批量梯度下降**和**随机梯度下降，采用不同的学习率并进行MSE曲线展示，分析选择最佳的学习率。
特别需要注意：
- 划分数据集时尽可能保持数据分布的一致性，保持样本类别比例相似，可采用分层采样的方式。
- 需要对数据集进行一定的预处理
### 中级要求
探究回归模型在机器学习和统计学上的差异。
- 回归模型在机器学习领域和统计学领域中都十分常用，而且使用方法也相似，但其实际的含义具有本质的区别。我们希望同学们从回归模型的角度更加充分地理解机器学习和统计学的区别。
### 高级要求
编程实现岭回归算法，求解训练样本的岭回归模型，平均训练误差和平均测试误差（解析法、批量梯度下降法和随机梯度下降法**均可**）。


## 实验三：参数估计和非参数估计
1. **初级要求**：生成两个各包含 $N=1000$ 个二维随机向量的数据集合 $X_1$ 和 $X_2$，数据集合中随机向量来自于三个分布模型，分别满足均值向量 $\mu_1=[1,4]$,$\mu_2=[4,1]$, $\mu_3=[8,4]$ 和协方差矩阵 $D_1=D_2=D_3=2\pmb{I}$ ，其中$\pmb{I}$是 $2*2$的单位矩阵。在生成数据集合 $X_1$ 时，假设来自三个分布模型的先验概率相同 ；而在生成数据集合 $X_2$ 时，先验概率如下：$p(w_1)=0.6$，$p(w_2)=0.3$，$p(w_3)=0.1$。在两个数据集合上分别应用“似然率测试规则”和“最大后验概率规则” 进行分类实验，计算分类错误率，分析实验结果。
2. **中级要求**：在两个数据集合上使⽤⾼斯核函数估计方法，应⽤“似然率测试规则”分类和“最大后验概率规则”在 [0.1, 0.5, 1, 1.5, 2] 范围内交叉验证找到最优 h 值，分析实验结果。
3. **高级要求**：在两个数据集合上使⽤进⾏k-近邻概率密度估计，计算并分析$k=1，3，5$时的概率密度估计结果。

## 实验四：朴素贝叶斯分类器
1. **初级要求**：采用分层采样的方式将数据集划分为训练集和测试集；给定编写一个朴素贝叶斯分类器，对测试机进行预测，计算分类准确率
2. **中级要求**：使用测试机评估模型，得到混淆矩阵、精度、召回率、F值
3. **高级要求**：在中级要求的基础上画出三类数据的ROC曲线，并求出AUC值