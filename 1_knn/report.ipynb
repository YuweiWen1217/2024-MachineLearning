{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验一报告\n",
    "文昱韦 2213125\n",
    "\n",
    "#### 实验一：基于kNN 的手写数字识别\n",
    "实验条件：给定semeion手写数字数据集，给定kNN分类算法\n",
    "实验要求：\n",
    "1. 初级要求：编程实现kNN算法；给出在不同k值（5，9，13）情况下，kNN算法对手写数字的识别精度（要求采用留一法）\n",
    "2. 中级要求：与机器学习包或平台(如weka)中的kNN分类器结果进行对比，性能指标为精度ACC，其他指标如归一化互信息NMI、混淆熵CEN任选其一（或两者）\n",
    "3. 高级要求：采用旋转等手段对原始数据进行处理，进行至少两个方向（左上，左下）旋转，采用CNN或其他深度学习方法实现手写体识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先导入相关工具包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split\n",
    "from sklearn.metrics import normalized_mutual_info_score, confusion_matrix, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.ndimage import rotate\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们定义三个会用到的函数：\n",
    "\n",
    "1. **euclidean_distance(a, b)**：计算两个向量$a$和$b$ 之间的欧几里得距离：\n",
    "     $$\n",
    "     d(a, b) = \\sqrt{\\sum_{i=1}^{n} (a_i - b_i)^2}\n",
    "     $$\n",
    "     \n",
    "2. **calculate_nmi(labels, predictions)**：计算真实结果（标签）与预测结果之间的归一化互信息（NMI）。我们通过sklearn里的函数完成计算。\n",
    "\n",
    "3. **calculate_cen(y_true, y_pred)**：计算混淆熵（CEN）。CEN 的公式为：\n",
    "     $$\n",
    "     CEN = -\\sum_{i,j} P(i, j) \\log(P(i, j))\n",
    "     $$\n",
    "   其中 $P(i, j)$是混淆矩阵的概率分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "def calculate_nmi(labels, predictions):\n",
    "    return normalized_mutual_info_score(labels, predictions)\n",
    "def calculate_cen(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    probs = cm / np.sum(cm)\n",
    "    cen = -np.nansum(probs * np.log(probs + 1e-10))\n",
    "    return cen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义函数加载 Semeion 手写数字数据集，并进行预处理。**X**储存前 256 列表示图像的像素特征；将后 10 列one-hot 编码格式的标签的通过 `np.argmax` 转换为单一的数字标签（即0 到 9 之间的整数）储存在**y**中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_semeion_data(file_path):\n",
    "    data = np.loadtxt(file_path)\n",
    "    # 前256列是特征，后10列是one-hot编码的标签\n",
    "    X = data[:, :256]\n",
    "    # 将one-hot编码转换为单一的数字标签\n",
    "    y = np.argmax(data[:, 256:], axis=1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是**初级要求**，即自己编程实现kNN，主要定义了两个函数。`knn_with_loocv`函数按照题目要求使用留一法评估分类器性能，并记录相关性能指标，它将训练集、测试集以及多个k值传入另一个函数`k_nearest_neighbors`，实现 kNN 分类。我们首先计算了测试样本与每个训练样本之间的距离并排序，然后对于每个给定的 $ k $ 值，我们选择距离最近的 $ k $ 个样本，并通过统计这 $ k $ 个样本中最常见的标签来进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(train_data, train_labels, test_sample, k_values):\n",
    "    distances = []\n",
    "    # 计算测试样本与每个训练样本之间的距离并排序\n",
    "    for i in range(len(train_data)):\n",
    "        dist = euclidean_distance(train_data[i], test_sample)\n",
    "        distances.append((dist, train_labels[i]))\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    predictions = [] # 储存该测试样本的三个预测值\n",
    "    # 遍历 k_values 中的 k 值，获取每个 k 值对应的分类结果\n",
    "    for k in k_values:\n",
    "        k_neighbors = [distances[i][1] for i in range(k)]\n",
    "        most_common = Counter(k_neighbors).most_common(1)\n",
    "        predictions.append(most_common[0][0])\n",
    "    return predictions\n",
    "\n",
    "# 进行kNN分类，并使用留一法进行验证\n",
    "def knn_with_loocv(data, labels, k_values):\n",
    "    loo = LeaveOneOut()\n",
    "    # 初始化一个字典，存储每个k值对应的预测结果\n",
    "    predictions_dict = {k: {'correct':[], 'predictions':[], 'true_labels':[]} for k in k_values}\n",
    "    # 留一法遍历数据\n",
    "    for train_index, test_index in loo.split(data):\n",
    "        train_data, test_data = data[train_index], data[test_index]\n",
    "        train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "        predictions = k_nearest_neighbors(train_data, train_labels, test_data[0], k_values)\n",
    "        \n",
    "        # 将每个k值对应的预测存储到对应的列表中\n",
    "        for i, k in enumerate(k_values):\n",
    "            predictions_dict[k]['correct'].append(int(predictions[i] == test_labels[0]))\n",
    "            predictions_dict[k]['predictions'].append(predictions[i])\n",
    "            predictions_dict[k]['true_labels'].append(test_labels[0])\n",
    "    # 计算每个k值的平均值\n",
    "    accuracies = []\n",
    "    for k in k_values:\n",
    "        accuracy = np.mean(predictions_dict[k]['correct'])\n",
    "        nmi = calculate_nmi(predictions_dict[k]['true_labels'], predictions_dict[k]['predictions'])\n",
    "        cen = calculate_cen(predictions_dict[k]['true_labels'], predictions_dict[k]['predictions'])\n",
    "        accuracies.append((accuracy, nmi, cen))\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面**中级要求**，即使用 sklearn 的 kNN 分类器进行对比的部分，主要定义了一个函数 `compare_with_sklearn_knn`。这个函数遍历不同的$ k $ 值，利用 sklearn 的 `KNeighborsClassifier` 来评估模型性能。我们依旧使用留一法交叉验证，将数据集划分为训练集和测试集。在每次迭代中，我们拟合训练数据，并对测试样本进行预测，将预测结果和真实标签保存下来。之后，我们计算模型的准确率 (ACC)、归一化互信息 (NMI) 和混淆熵 (CEN)。最后，函数返回所有 $ k $ 值对应的准确率、NMI 和 CEN。这一部分为中级要求提供了性能对比，有助于验证自定义 kNN 实现的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# sklearn\n",
    "#################################\n",
    "# 使用Scikit-learn的kNN分类器进行对比\n",
    "def compare_with_sklearn_knn(X, y, k_values):\n",
    "    accuracies = []\n",
    "    nmis = []\n",
    "    cens = []\n",
    "    # 遍历不同的k值\n",
    "    for k in k_values:\n",
    "        # 使用Sklearn的KNeighborsClassifier\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        loo = LeaveOneOut()\n",
    "        predictions = []\n",
    "        true_labels = []\n",
    "        for train_index, test_index in loo.split(X):\n",
    "            train_data, test_data = X[train_index], X[test_index]\n",
    "            train_labels, test_labels = y[train_index], y[test_index]\n",
    "            # 拟合并预测\n",
    "            knn.fit(train_data, train_labels)\n",
    "            prediction = knn.predict(test_data)\n",
    "            predictions.append(prediction[0])\n",
    "            true_labels.append(test_labels[0])\n",
    "        # 计算 ACC, NMI, CEN\n",
    "        acc = accuracy_score(true_labels, predictions)\n",
    "        nmi = calculate_nmi(true_labels, predictions)\n",
    "        cen = calculate_cen(true_labels, predictions)\n",
    "        accuracies.append(acc)\n",
    "        nmis.append(nmi)\n",
    "        cens.append(cen)\n",
    "    return accuracies, nmis, cens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是**高级要求**关于图像旋转和 CNN 模型构建的部分，我们定义了两个主要函数。\n",
    "\n",
    "`augment_data(X, y)`函数主要是对图像进行左上和左下方向的旋转。我们首先使用 `rotate` 函数将每个图像顺时针旋转 20 度和逆时针旋转 20 度，并将旋转后的图像展平，形成了一个新的数据集。\n",
    "\n",
    "`build_cnn(input_shape, num_classes)`函数主要用于构建CNN模型。我们首先定义模型的输入形状和类别数。模型包括多个卷积层和池化层，以提取特征和降低维度。最后通过 `Flatten` 层将数据展平，并添加全连接层，输出类别预测。我们使用 `softmax` 激活函数以获取每个类别的概率，并采用 `categorical_crossentropy` 作为损失函数，优化器选用 Adam。函数返回构建好的模型，准备进行训练和评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# 旋转后使用CNN进行识别\n",
    "#################################\n",
    "# 数据增强：对图像进行左上、左下旋转\n",
    "def augment_data(X, y):\n",
    "    X_rotated_left_up = np.array([rotate(x.reshape(16, 16), angle=20, reshape=False).flatten() for x in X])\n",
    "    X_rotated_left_down = np.array([rotate(x.reshape(16, 16), angle=-20, reshape=False).flatten() for x in X])\n",
    "    \n",
    "    # 将原始数据和增强数据拼接\n",
    "    X_augmented = np.concatenate([X_rotated_left_up, X_rotated_left_down], axis=0)\n",
    "    y_augmented = np.concatenate([y, y], axis=0)\n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "# 构建CNN模型\n",
    "def build_cnn(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面就是实验的主要执行部分，我们分别实现了自定义 kNN 分类、与 Scikit-learn 的 kNN 进行对比，以及使用 CNN 进行分类。\n",
    "\n",
    "对于**自行实现 kNN**，我们首先加载数据集，并设置不同的 k  值，然后调用 `knn_with_loocv` 函数，传入特征和标签，得到每个  k 值的准确率、NMI 和 CEN并输出。\n",
    "\n",
    "对于**sklearn 实现 kNN**，我们调用 `compare_with_sklearn_knn` 函数，输出每个  k  值的准确率、NMI 和 CEN，我们可以直观地比较自定义 kNN 实现和 Skit-learn 实现之间的差异。\n",
    "\n",
    "对于**使用CNN 进行分类**，我们通过 `augment_data` 函数对原始图像进行旋转，然后对数据进行了预处理，调整形状以适应 CNN 输入格式，并将标签进行了转换；调用 `build_cnn` 函数构建 CNN 模型在训练集上进行训练、在测试集上进行预测，输出模型的准确率、NMI 和 CEN。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自行实现kNN\n",
      "k=5 时的精度: 0.9140, NMI: 0.8372, CEN: 2.6725\n",
      "k=9 时的精度: 0.9240, NMI: 0.8515, CEN: 2.6403\n",
      "k=13 时的精度: 0.9153, NMI: 0.8377, CEN: 2.6711\n",
      "sklearn实现kNN\n",
      "k=5 时的精度: 0.9052, NMI: 0.8293, CEN: 2.6879\n",
      "k=9 时的精度: 0.9115, NMI: 0.8336, CEN: 2.6796\n",
      "k=13 时的精度: 0.9033, NMI: 0.8224, CEN: 2.7043\n"
     ]
    }
   ],
   "source": [
    "print(\"自行实现kNN\")\n",
    "# 加载数据\n",
    "file_path = 'semeion.data'\n",
    "X, y = load_semeion_data(file_path)\n",
    "# 设定不同的k值\n",
    "k_values = [5, 9, 13]\n",
    "# 传入k值数组，得到每个k值的精度\n",
    "results = knn_with_loocv(X, y, k_values)\n",
    "# 输出每个k值对应的准确率\n",
    "for i, k in enumerate(k_values):\n",
    "    accuracy, nmi, cen = results[i]\n",
    "    print(f'k={k} 时的精度: {accuracy:.4f}, NMI: {nmi:.4f}, CEN: {cen:.4f}')\n",
    "\n",
    "print(\"sklearn实现kNN\")\n",
    "# 调用对比函数并输出结果\n",
    "sklearn_accuracies, sklearn_nmis, sklearn_cens = compare_with_sklearn_knn(X, y, k_values)\n",
    "# 输出Sklearn kNN分类器的结果\n",
    "for i, k in enumerate(k_values):\n",
    "    print(f'k={k} 时的精度: {sklearn_accuracies[i]:.4f}, NMI: {sklearn_nmis[i]:.4f}, CEN: {sklearn_cens[i]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像旋转后使用CNN进行分类\n",
      "Epoch 1/10\n",
      "81/81 [==============================] - 1s 5ms/step - loss: 1.6667 - accuracy: 0.4527 - val_loss: 1.1270 - val_accuracy: 0.6132\n",
      "Epoch 2/10\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.9027 - accuracy: 0.7105 - val_loss: 0.8532 - val_accuracy: 0.7387\n",
      "Epoch 3/10\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.7071 - accuracy: 0.7698 - val_loss: 0.7034 - val_accuracy: 0.7735\n",
      "Epoch 4/10\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.8298 - val_loss: 0.5695 - val_accuracy: 0.8049\n",
      "Epoch 5/10\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.8581 - val_loss: 0.5256 - val_accuracy: 0.8293\n",
      "Epoch 6/10\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8833 - val_loss: 0.5519 - val_accuracy: 0.8049\n",
      "Epoch 7/10\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.3171 - accuracy: 0.9058 - val_loss: 0.5440 - val_accuracy: 0.8328\n",
      "Epoch 8/10\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.9213 - val_loss: 0.5770 - val_accuracy: 0.8258\n",
      "Epoch 9/10\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.2314 - accuracy: 0.9271 - val_loss: 0.3852 - val_accuracy: 0.8606\n",
      "Epoch 10/10\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.1949 - accuracy: 0.9403 - val_loss: 0.4484 - val_accuracy: 0.8432\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "准确率: 0.9091\n",
      "NMI: 0.8453\n",
      "CEN: 2.6378\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"图像旋转后使用CNN进行分类\")\n",
    "X_augmented, y_augmented = augment_data(X, y)\n",
    "X_augmented = X_augmented.reshape(-1, 16, 16, 1)  # 将数据重塑为适合CNN输入的格式\n",
    "y_augmented_categorical = to_categorical(y_augmented)  # 将标签转换为one-hot编码\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_augmented, y_augmented_categorical, test_size=0.1, random_state=42)\n",
    "# 构建CNN模型\n",
    "input_shape = (16, 16, 1)\n",
    "num_classes = 10  # 手写数字类别数\n",
    "model = build_cnn(input_shape, num_classes)\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "# 测试模型\n",
    "y_test_labels = np.argmax(y_test, axis=1)  # 转换one-hot编码为标签\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)  # 模型预测标签\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "# 计算NMI和CEN\n",
    "nmi = calculate_nmi(y_test_labels, y_pred)\n",
    "cen = calculate_cen(y_test_labels, y_pred)\n",
    "# 输出结果\n",
    "print(f'准确率: {accuracy:.4f}')\n",
    "print(f'NMI: {nmi:.4f}')\n",
    "print(f'CEN: {cen:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实验结果分析\n",
    "\n",
    "1. **自定义 kNN 实现**：\n",
    "   - 在自定义实现的 kNN 中，我们观察到对于 $ k = 9 $ 时，模型表现最佳，准确率达到 0.9240，NMI 为 0.8515，CEN 为 2.6403。这表明选择合适的 $ k $ 值可以显著提高分类性能。\n",
    "   - 其他 $ k $ 值的表现也相对稳定，尤其是 $ k = 5 $ 和 $ k = 13 $，分别获得了 0.9140 和 0.9153 的准确率。这说明自定义的 kNN 实现有效地捕捉了数据特征。\n",
    "   - 对比 Scikit-learn 的 kNN 实现，我们发现其在相同 $ k $ 值下的准确率均低于自定义实现，尤其在 $ k = 5 $ 和 $ k = 9 $ 时，差距明显，分别为 0.9052 和 0.9115。这表明自定义实现可能在特定数据集上更具优势。\n",
    "\n",
    "2. **使用 Scikit-learn 的 kNN 实现**：\n",
    "   - Scikit-learn 的 kNN 分类器在所有 $ k $ 值下的准确率、NMI 和 CEN 指标均低于自定义实现，显示出其在本实验中相对较弱的性能。\n",
    "\n",
    "3. **图像旋转后使用 CNN 进行分类**：\n",
    "   - 图像旋转后，我们构建了 CNN 模型并进行了训练。最终模型在测试集上获得准确率0.9091，NMI 为0.8453，CEN 为 2.6378。这表明即使图像进行了旋转，CNN在处理图像分类任务中仍有强大的能力。\n",
    "\n",
    "#### 总体结论\n",
    "- 自己实现的 kNN 实现优于 Scikit-learn 的实现，尤其在特定 $ k $ 值下表现突出。\n",
    "- CNN 在图像旋转后仍有较高的分类精度，显示了深度学习在手写数字识别任务中的有效性。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
